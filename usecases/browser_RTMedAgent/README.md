# ğŸ§  RTMedAgent â€“ Real-Time Voice AI Assistant (Browser-Based)

Enable **real-time voice-to-voice healthcare interactions** using Azure Speech Services and GPT. This browser-based application listens to patient speech, interprets intent using AI, and responds with synthesized speech via Azure Text-to-Speech (TTS)â€”all in real time.

## ğŸ“‚ Folder Structure

```
usecases/
â””â”€â”€ browser_RTMedAgent/
    â”œâ”€â”€ backend/               # WebSocket server with GPT integration (Python)
    â”œâ”€â”€ frontend/              # React + Vite UI powered by Azure Speech SDK
    â”œâ”€â”€ test_cases_scenarios/  # Optional test scripts and scenarios
    â””â”€â”€ README.md              # This file
```

## ğŸ§ª Use Case Summary

> #### **ğŸ“ Real-Time Voice AI for Healthcare**
>
> RTMedAgent showcases how to deliver real-time, AI-driven healthcare conversations using Azure and OpenAI services. It transforms natural patient speech into actionable, structured outcomes through a seamless, interactive system.

## ğŸš€ Getting Started

### 1. ğŸ”§ Start the Backend
### ğŸ›°ï¸ Using Azure Communication Services (ACS) for Calling

If you want to enable outbound calling via Azure Communication Services (ACS):

1. **Create a Dev Tunnel for Local Backend Access**

    ACS requires your backend to be accessible from the public internet. Use [Azure Dev Tunnel](https://learn.microsoft.com/en-us/azure/developer/dev-tunnels/overview) to expose your local backend on port `8010`:

    ```bash
    devtunnel create --allow-anonymous
    devtunnel port create -p 8010
    devtunnel host    
    ```

    This will provide a public URL (e.g., `https://<random>-<port>.use.devtunnels.ms`). Use this URL for your ACS webhook configuration.
    Set this as your `BASE_URL` value on your python .env

2. **Update Environment Variables**

    - Copy `.env.sample` to `.env` in the `frontend` directory:

      ```bash
      cp .env.sample .env
      ```

    - Edit `.env` and update the following variables as needed:

      ```env
      VITE_AZURE_SPEECH_KEY=your_speech_key
      VITE_AZURE_REGION=your_region
      VITE_WS_URL=wss://<your-devtunnel>.devtunnels.ms/realtime
      ```

    Replace `<your-devtunnel>` with the public Dev Tunnel URL from step 1.

3. **Configure ACS Webhook**

    In your Azure Communication Services resource, set the webhook/callback URL to your Dev Tunnel endpoint (e.g., `https://<your-devtunnel>.devtunnels.ms/api/acs-callback`).

---
Navigate to the `backend` folder and start the WebSocket server:

```bash
cd usecases/browser_RTMedAgent/backend
pip install -r requirements.txt
python server.py
```

âœ… The WebSocket server will start at: `ws://localhost:8010/realtime`

### 2. ğŸ’» Start the Frontend

In a new terminal, navigate to the `frontend` folder and start the UI:

```bash
cd usecases/browser_RTMedAgent/frontend
npm install
npm run dev
```

âœ… The UI will be available at: `http://localhost:5173`

### ğŸ”‘ Environment Setup (Optional)

If supported, create a `.env` file in the `frontend` directory with the following variables:

```env
VITE_AZURE_SPEECH_KEY=your_speech_key
VITE_AZURE_REGION=your_region
VITE_WS_URL=ws://localhost:8010/realtime
```

If `.env` is not supported, manually update these constants in `App.jsx`.

## ğŸ› ï¸ System Overview

- **ğŸ¤ Speech-to-Text (STT):** Azure Speech SDK
- **ğŸ§  AI Reasoning:** Azure OpenAI GPT (via backend)
- **ğŸ”Š Text-to-Speech (TTS):** Azure Neural Voices
- **ğŸ” Real-Time Streaming:** WebSocket for bidirectional communication
- **ğŸ–¥ï¸ Frontend:** React + Vite

This system enables seamless, real-time voice interactions for healthcare applications.