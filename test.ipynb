{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e24e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# set the directory to the location of the script\n",
    "try:\n",
    "    target_directory = os.getenv(\n",
    "        \"TARGET_DIRECTORY\", os.getcwd()\n",
    "    )  # Use environment variable if available\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "except Exception as e:\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3bbccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Templates found: ['voice_agent_authentication.jinja', 'voice_agent_system.jinja']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import contextlib\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# GPT, TTS, tools\n",
    "from openai import AzureOpenAI\n",
    "from src.speech.text_to_speech import SpeechSynthesizer\n",
    "from usecases.browser_RTMedAgent.backend.tools import available_tools\n",
    "from usecases.browser_RTMedAgent.backend.functions import (\n",
    "    schedule_appointment,\n",
    "    refill_prescription,\n",
    "    lookup_medication_info,\n",
    "    evaluate_prior_authorization,\n",
    "    escalate_emergency,\n",
    "    authenticate_user,\n",
    ")\n",
    "from usecases.browser_RTMedAgent.backend.prompt_manager import PromptManager\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Globals & helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "STOP_WORDS = [\"goodbye\", \"exit\", \"see you later\", \"bye\"]\n",
    "logger = get_logger()\n",
    "prompt_manager = PromptManager()\n",
    "\n",
    "az_openai_client = AzureOpenAI(\n",
    "    api_version=\"2025-02-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    ")\n",
    "\n",
    "az_speech_synthesizer_client = SpeechSynthesizer()\n",
    "\n",
    "function_mapping = {\n",
    "    \"schedule_appointment\": schedule_appointment,\n",
    "    \"refill_prescription\": refill_prescription,\n",
    "    \"lookup_medication_info\": lookup_medication_info,\n",
    "    \"evaluate_prior_authorization\": evaluate_prior_authorization,\n",
    "    \"escalate_emergency\": escalate_emergency,\n",
    "    \"authenticate_user\": authenticate_user,\n",
    "}\n",
    "\n",
    "\n",
    "def check_for_stopwords(prompt: str) -> bool:\n",
    "    return any(stop_word in prompt.lower() for stop_word in STOP_WORDS)\n",
    "\n",
    "\n",
    "async def speak_and_log(text: str):\n",
    "    print(f\"[Agent ðŸ—£ï¸]: {text}\")\n",
    "    try:\n",
    "        az_speech_synthesizer_client.start_speaking_text(text)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error synthesizing TTS: {e}\")\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self, auth: bool = True, pm: Optional[PromptManager] = None):\n",
    "        self.pm = pm or PromptManager()\n",
    "        self.cid = str(uuid.uuid4())[:8]\n",
    "        if auth:\n",
    "            prompt = self.pm.get_prompt(\"voice_agent_authentication.jinja\")\n",
    "            self.hist = [{\"role\": \"system\", \"content\": prompt}]\n",
    "        else:\n",
    "            prompt = self.pm.get_prompt(\"voice_agent_system.jinja\")\n",
    "            self.hist = [{\"role\": \"system\", \"content\": prompt}]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Shared: GPT streaming response + tool handling\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_gpt_response(convo_manager: ConversationManager, user_prompt: str):\n",
    "    tool_call_id = None\n",
    "    tool_name = None\n",
    "    function_call_arguments = \"\"\n",
    "    collected_messages: List[str] = []\n",
    "    tts_sentence_end = [\".\", \"!\", \"?\", \";\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \"ï¼›\", \"\\n\"]\n",
    "\n",
    "    convo_manager.hist.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    try:\n",
    "        response = az_openai_client.chat.completions.create(\n",
    "            stream=True,\n",
    "            messages=convo_manager.hist,\n",
    "            tools=available_tools,\n",
    "            tool_choice=\"auto\",\n",
    "            max_tokens=4096,\n",
    "            temperature=0.5,\n",
    "            top_p=1.0,\n",
    "            model=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\"),\n",
    "        )\n",
    "\n",
    "        full_response = \"\"\n",
    "        tool_call_started = False\n",
    "\n",
    "        for chunk in response:\n",
    "            if not chunk.choices:\n",
    "                continue\n",
    "\n",
    "            delta = chunk.choices[0].delta\n",
    "\n",
    "            # ðŸ”„ Collect tool_call fragments\n",
    "            if delta.tool_calls:\n",
    "                tool_call = delta.tool_calls[0]\n",
    "\n",
    "                # Capture tool_call ID, name, and append args progressively\n",
    "                tool_call_id = tool_call.id or tool_call_id\n",
    "                if tool_call.function.name:\n",
    "                    tool_name = tool_call.function.name\n",
    "                if tool_call.function.arguments:\n",
    "                    function_call_arguments += tool_call.function.arguments\n",
    "                tool_call_started = True\n",
    "                continue\n",
    "\n",
    "            # ðŸŽ¤ Regular streaming assistant message\n",
    "            if delta.content:\n",
    "                chunk_text = delta.content\n",
    "                collected_messages.append(chunk_text)\n",
    "                full_response += chunk_text\n",
    "\n",
    "                if chunk_text.strip() in tts_sentence_end:\n",
    "                    text_to_speak = \"\".join(collected_messages).strip()\n",
    "                    if text_to_speak:\n",
    "                        await speak_and_log(text_to_speak)\n",
    "                        collected_messages.clear()\n",
    "\n",
    "        final_text = \"\".join(collected_messages).strip()\n",
    "        if final_text:\n",
    "            await speak_and_log(final_text)\n",
    "\n",
    "        # ðŸ’¬ Only append assistant text if it was non-empty\n",
    "        if full_response.strip():\n",
    "            convo_manager.hist.append(\n",
    "                {\"role\": \"assistant\", \"content\": full_response.strip()}\n",
    "            )\n",
    "\n",
    "        # ðŸ§  Append tool_call only if fully detected\n",
    "        if tool_call_started and tool_call_id and tool_name and function_call_arguments:\n",
    "            convo_manager.hist.append(\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": None,\n",
    "                    \"tool_calls\": [\n",
    "                        {\n",
    "                            \"id\": tool_call_id,\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"name\": tool_name,\n",
    "                                \"arguments\": function_call_arguments,\n",
    "                            },\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            tool_result = await handle_tool_call(\n",
    "                tool_name, tool_call_id, function_call_arguments, convo_manager\n",
    "            )\n",
    "            if tool_name == \"authenticate_user\":\n",
    "                return tool_result\n",
    "\n",
    "    except asyncio.CancelledError:\n",
    "        logger.info(f\"ðŸ”š process_gpt_response cancelled for input: '{user_prompt[:40]}'\")\n",
    "        raise\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Handle tool call\n",
    "# ---------------------------------------------------------------------------\n",
    "async def handle_tool_call(\n",
    "    tool_name, tool_id, function_call_arguments, convo_manager: ConversationManager\n",
    "):\n",
    "    logger.info(f\"tool_name: {tool_name}\")\n",
    "    logger.info(f\"tool_id: {tool_id}\")\n",
    "    logger.info(f\"function_call_arguments: {function_call_arguments}\")\n",
    "\n",
    "    try:\n",
    "        parsed_args = json.loads(function_call_arguments.strip() or \"{}\")\n",
    "        function_to_call = function_mapping.get(tool_name)\n",
    "\n",
    "        if function_to_call:\n",
    "            result_json = await function_to_call(parsed_args)\n",
    "            logger.info(f\"âœ… Function '{tool_name}' executed. Result: {result_json}\")\n",
    "\n",
    "            if isinstance(result_json, str):\n",
    "                result = json.loads(result_json)\n",
    "            else:\n",
    "                result = result_json\n",
    "\n",
    "            convo_manager.hist.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": tool_name,\n",
    "                    \"content\": json.dumps(result),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            await process_tool_followup(convo_manager)\n",
    "            return result\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"âŒ Error parsing function arguments: {e}\")\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# GPT follow-up after tool completes\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_tool_followup(convo_manager: ConversationManager):\n",
    "    collected_messages: List[str] = []\n",
    "    tts_sentence_end = [\".\", \"!\", \"?\", \";\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \"ï¼›\", \"\\n\"]\n",
    "\n",
    "    response = az_openai_client.chat.completions.create(\n",
    "        stream=True,\n",
    "        messages=convo_manager.hist,\n",
    "        temperature=0.5,\n",
    "        top_p=1.0,\n",
    "        max_tokens=4096,\n",
    "        model=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\"),\n",
    "    )\n",
    "\n",
    "    full_response = \"\"\n",
    "\n",
    "    for chunk in response:\n",
    "        if not chunk.choices:\n",
    "            continue\n",
    "        delta = chunk.choices[0].delta\n",
    "        if hasattr(delta, \"content\") and delta.content:\n",
    "            chunk_message = delta.content\n",
    "            collected_messages.append(chunk_message)\n",
    "            full_response += chunk_message\n",
    "\n",
    "            if chunk_message.strip() in tts_sentence_end:\n",
    "                text_to_speak = \"\".join(collected_messages).strip()\n",
    "                if text_to_speak:\n",
    "                    await speak_and_log(text_to_speak)\n",
    "                    collected_messages.clear()\n",
    "\n",
    "    final_text = \"\".join(collected_messages).strip()\n",
    "    if final_text:\n",
    "        await speak_and_log(final_text)\n",
    "        convo_manager.hist.append({\"role\": \"assistant\", \"content\": final_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19aaab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 12:02:24,261 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Hello from XMYX Healthcare Com... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Hello from XMYX Healthcare Com...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Templates found: ['voice_agent_authentication.jinja', 'voice_agent_system.jinja']\n",
      "[Agent ðŸ—£ï¸]: Hello from XMYX Healthcare Company! Before I can assist you, letâ€™s verify your identity. How may I address you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 12:02:24,876 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Thank you, Alice.... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Thank you, Alice....\n",
      "2025-04-18 12:02:24,884 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Could you please provide your ... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Could you please provide your ...\n",
      "2025-04-18 12:02:24,906 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Please say it in the format \"M... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Please say it in the format \"M...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent ðŸ—£ï¸]: Thank you, Alice.\n",
      "[Agent ðŸ—£ï¸]: Could you please provide your date of birth?\n",
      "[Agent ðŸ—£ï¸]: Please say it in the format \"Month Day, Year.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 12:02:25,346 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Thank you for providing your d... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Thank you for providing your d...\n",
      "2025-04-18 12:02:25,351 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Let me confirm it with you: Ap... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Let me confirm it with you: Ap...\n",
      "2025-04-18 12:02:25,354 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Is that correct?... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Is that correct?...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent ðŸ—£ï¸]: Thank you for providing your date of birth.\n",
      "[Agent ðŸ—£ï¸]: Let me confirm it with you: April 12, 1987.\n",
      "[Agent ðŸ—£ï¸]: Is that correct?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 12:02:25,913 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Thank you, Alice.... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Thank you, Alice....\n",
      "2025-04-18 12:02:25,949 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Let me confirm your phone numb... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Let me confirm your phone numb...\n",
      "2025-04-18 12:02:25,953 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Is that correct?... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Is that correct?...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent ðŸ—£ï¸]: Thank you, Alice.\n",
      "[Agent ðŸ—£ï¸]: Let me confirm your phone number: 5 5 5 2 9 7 1 0 7 8.\n",
      "[Agent ðŸ—£ï¸]: Is that correct?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 12:02:26,418 - micro - MainProcess - INFO     tool_name: authenticate_user (2681065656.py:handle_tool_call:167)\n",
      "INFO:micro:tool_name: authenticate_user\n",
      "2025-04-18 12:02:26,420 - micro - MainProcess - INFO     tool_id: call_Eq2HrrfloZaVT5cvFnau02QH (2681065656.py:handle_tool_call:168)\n",
      "INFO:micro:tool_id: call_Eq2HrrfloZaVT5cvFnau02QH\n",
      "2025-04-18 12:02:26,422 - micro - MainProcess - INFO     function_call_arguments: {\"first_name\":\"Alice\",\"last_name\":\"Brown\",\"phone_number\":\"5552971078\"} (2681065656.py:handle_tool_call:169)\n",
      "INFO:micro:function_call_arguments: {\"first_name\":\"Alice\",\"last_name\":\"Brown\",\"phone_number\":\"5552971078\"}\n",
      "2025-04-18 12:02:26,425 - micro - MainProcess - INFO     ðŸ”Ž Checking user: Alice Brown with phone: 5552971078 (functions.py:authenticate_user:135)\n",
      "INFO:micro:ðŸ”Ž Checking user: Alice Brown with phone: 5552971078\n",
      "2025-04-18 12:02:26,427 - micro - MainProcess - INFO     ðŸ“ž Cleaned stored phone: 5552971078 (functions.py:authenticate_user:149)\n",
      "INFO:micro:ðŸ“ž Cleaned stored phone: 5552971078\n",
      "2025-04-18 12:02:26,430 - micro - MainProcess - INFO     ðŸ“ž Cleaned input phone:  5552971078 (functions.py:authenticate_user:150)\n",
      "INFO:micro:ðŸ“ž Cleaned input phone:  5552971078\n",
      "2025-04-18 12:02:26,433 - micro - MainProcess - INFO     âœ… Authentication succeeded for Alice Brown (functions.py:authenticate_user:153)\n",
      "INFO:micro:âœ… Authentication succeeded for Alice Brown\n",
      "2025-04-18 12:02:26,436 - micro - MainProcess - INFO     âœ… Function 'authenticate_user' executed. Result: {'authenticated': True, 'message': 'Authenticated Alice Brown.', 'patient_id': 'P54321'} (2681065656.py:handle_tool_call:177)\n",
      "INFO:micro:âœ… Function 'authenticate_user' executed. Result: {'authenticated': True, 'message': 'Authenticated Alice Brown.', 'patient_id': 'P54321'}\n",
      "2025-04-18 12:02:26,803 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Thank you for verifying your i... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Thank you for verifying your i...\n",
      "2025-04-18 12:02:26,807 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): Letâ€™s continue.... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): Letâ€™s continue....\n",
      "2025-04-18 12:02:26,811 - micro - MainProcess - INFO     [ðŸ”Š] Speaking text (server speaker): How can I assist you today?... (text_to_speech.py:start_speaking_text:55)\n",
      "INFO:micro:[ðŸ”Š] Speaking text (server speaker): How can I assist you today?...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent ðŸ—£ï¸]: Thank you for verifying your information, Alice.\n",
      "[Agent ðŸ—£ï¸]: Letâ€™s continue.\n",
      "[Agent ðŸ—£ï¸]: How can I assist you today?\n",
      "âœ… Authenticated\n"
     ]
    }
   ],
   "source": [
    "cm = ConversationManager(auth=True)\n",
    "await speak_and_log(\n",
    "    (\n",
    "        \"Hello from XMYX Healthcare Company! Before I can assist you, \"\n",
    "        \"letâ€™s verify your identity. How may I address you?\"\n",
    "    )\n",
    ")\n",
    "cm.hist.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello from XMYX Healthcare Company! Before I can assist you, \"\n",
    "        \"letâ€™s verify your identity. How may I address you?\",\n",
    "    }\n",
    ")\n",
    "user_input = \"My name is Alice Brown.\"\n",
    "await process_gpt_response(cm, user_input)\n",
    "user_input = \"I was born on 1987-04-12\"\n",
    "await process_gpt_response(cm, user_input)\n",
    "user_input = \"phone number is 5552971078\"\n",
    "await process_gpt_response(cm, user_input)\n",
    "user_input = \"Yes\"\n",
    "result = await process_gpt_response(cm, user_input)\n",
    "if result and result.get(\"authenticated\"):\n",
    "    print(\"âœ… Authenticated\")\n",
    "else:\n",
    "    print(\"âŒ Authentication failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0614b53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authenticated': True,\n",
       " 'message': 'Authenticated Alice Brown.',\n",
       " 'patient_id': 'P54321'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe7476ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"\\n\\n\\\"\\\"\\\"Task\\\"\\\"\\\"\\nYou are a professional and empathetic healthcare voice agent.  \\nYour sole responsibility in this phase is to **verify the identity** of the caller before providing any assistance\\u2014except in the case of an emergency.\\n\\n\\\"\\\"\\\"Purpose\\\"\\\"\\\"\\nProtect user privacy and ensure that only verified users receive assistance.  \\nDo **not** proceed to any service-related request until identity is confirmed, **unless** the call involves a possible emergency.\\n\\n---\\n\\n\\\"\\\"\\\"Instructions\\\"\\\"\\\"\\n\\n1. **Emergency Check**:\\n  - As the caller begins speaking, **carefully listen for any signs of an emergency** (e.g., chest pain, difficulty breathing, suicidal thoughts, etc.).\\n  - If an emergency is detected **at any point**, immediately trigger the internal tool:\\n    **`escalate_emergency`**\\n  - Respond with:\\n    > \\u201cThis sounds like an urgent medical issue. I\\u2019m going to escalate this right away so you can get immediate help.\\u201d\\n  - Skip all authentication steps and end the session after escalation.\\n\\n---\\n\\n2. **Identity Verification** (if no emergency is present):\\n  - Collect the following details:\\n    - **Full Name** \\u2192 Confirm by repeating the full name back to the caller.  \\n    - **Date of Birth** \\u2192 Provide guidance on the format (e.g., \\\"Month Day, Year\\\"). Confirm digit by digit (MM-DD-YYYY).  \\n    - **Phone Number or Patient ID** \\u2192 Confirm digit by digit. When the caller provides numbers (e.g., phone, DOB, IDs), **repeat each digit individually** for clarity.\\n  - Example:  \\n    > \\u201cLet me confirm I have your number correct: 3 1 2 5 5 5 0 1 2 1. Is that correct?\\u201d\\n  - Repeat and verify each piece of information before proceeding to the next. Ensure the caller explicitly confirms each detail.\\n  - If any detail is unclear or misheard, respond with:  \\n    > \\u201cI\\u2019m sorry, I didn\\u2019t quite catch that. Could you repeat it one digit at a time, please?\\u201d\\n\\n3. **Authentication**:\\n  - Once all information is collected and confirmed, trigger the **`authenticate_user`** tool with the captured details.\\n\\n4. **Post-Authentication Response**:\\n  - \\u2705 **If authentication is successful**:\\n    > \\u201cThank you for verifying your information. Let\\u2019s continue.\\u201d\\n  - \\u274c **If authentication fails**:\\n    > \\u201cI\\u2019m sorry, I couldn\\u2019t verify your information. For your safety, please contact our office directly.\\u201d\\n\\n---\\n\\n\\\"\\\"\\\"Important Guidelines\\\"\\\"\\\"\\n- Do **not** assist with appointments, medications, or any other request unless authentication is successful.\\n- Do **not** repeat sensitive medical details unless the user is verified.\\n- Always listen for emergency signals and respond immediately with escalation.\\n- Maintain a warm, calm, and supportive tone at all times.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Hello from XMYX Healthcare Company! Before I can assist you, let\\u2019s verify your identity. How may I address you?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"My name is Alice Brown.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Thank you, Alice. Could you please provide your date of birth? Please say it in the format \\\"Month Day, Year.\\\"\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"I was born on 1987-04-12\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Thank you for providing your date of birth. Let me confirm it with you: April 12, 1987. Is that correct?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"phone number is 5552971078\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Thank you, Alice. Let me confirm your phone number: 5 5 5 2 9 7 1 0 7 8. Is that correct?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Yes\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": null,\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_Eq2HrrfloZaVT5cvFnau02QH\",\n",
      "        \"type\": \"function\",\n",
      "        \"function\": {\n",
      "          \"name\": \"authenticate_user\",\n",
      "          \"arguments\": \"{\\\"first_name\\\":\\\"Alice\\\",\\\"last_name\\\":\\\"Brown\\\",\\\"phone_number\\\":\\\"5552971078\\\"}\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"tool_call_id\": \"call_Eq2HrrfloZaVT5cvFnau02QH\",\n",
      "    \"role\": \"tool\",\n",
      "    \"name\": \"authenticate_user\",\n",
      "    \"content\": \"{\\\"authenticated\\\": true, \\\"message\\\": \\\"Authenticated Alice Brown.\\\", \\\"patient_id\\\": \\\"P54321\\\"}\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(cm.hist, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
